{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Training_Demo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aeldemerdash/Essential-Machine-Learning-and-AI-with-Python-and-Jupyter-Notebook/blob/master/Copy_of_Training_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "TD1BTHDFt3nL",
        "colab_type": "code",
        "outputId": "5a20fe25-929e-4e46-91ac-8cd09457f323",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import pandas as pd\n",
        "from name_matching import Trainer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\amr-e\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "p8bPxJp7t3nn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Note: \n",
        "For this sample code to run successfully, you need to have followed all the installation steps in the code documentation.\n"
      ]
    },
    {
      "metadata": {
        "id": "_c2ZGYtBt3nr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training"
      ]
    },
    {
      "metadata": {
        "id": "YE_tsWpVt3nw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Importing english and arabic lists from the dataset excel file\n",
        "dfs = pd.read_excel('Datasets/Training_Sample_Set.xlsx', encoding='utf-8')\n",
        "En_list_Train = dfs['ENGLISH_APPLICANT_NAME'].tolist()\n",
        "Ar_list_Train = dfs['ARABIC_APPLICANT_NAME'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ry6pcXE7t3n5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initializing the trainer class\n",
        "En2Ar_model_trainer = Trainer(En_list_Train, Ar_list_Train, 'english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p8cA2AXot3oA",
        "colab_type": "code",
        "outputId": "300db8d0-c003-496e-8ac2-a97ec19b9b28",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Performing preprocessing\n",
        "D = En2Ar_model_trainer.Preprocess()\n",
        "# As stated in the training documentation, the elements of the Dictionary D should replace\n",
        "# Initiations of the class NameMatcher in order to be able to use that class"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing ...........\n",
            "Number of samples: 4060\n",
            "Number of unique input tokens: 26\n",
            "Number of unique output tokens: 38\n",
            "Max sequence length for inputs: 20\n",
            "Max sequence length for outputs: 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B3WnMLhdt3oI",
        "colab_type": "code",
        "outputId": "584e607e-bdbc-4fda-ef44-988d44776d38",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Start Training\n",
        "# Tunable parameters\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "latent_dim = 256\n",
        "\n",
        "En2Ar_model_trainer.Train(batch_size, epochs, latent_dim)\n",
        "\n",
        "print('Input_chars:', D['Input_chars'])\n",
        "print('target_chars:', D['target_chars'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building the model ..........\n",
            "Starting training process ...........\n",
            "Epoch 1/20\n",
            "4060/4060 [==============================] - 8s 2ms/step - loss: 0.8105\n",
            "Epoch 2/20\n",
            " 128/4060 [..............................] - ETA: 5s - loss: 0.7109"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\amr-e\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\callbacks.py:526: RuntimeWarning: Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4060/4060 [==============================] - 5s 1ms/step - loss: 0.7169\n",
            "Epoch 3/20\n",
            "4060/4060 [==============================] - 5s 1ms/step - loss: 0.6495\n",
            "Epoch 4/20\n",
            "4060/4060 [==============================] - 5s 1ms/step - loss: 0.5832\n",
            "Epoch 5/20\n",
            "4060/4060 [==============================] - 5s 1ms/step - loss: 0.5427\n",
            "Epoch 6/20\n",
            "4060/4060 [==============================] - 5s 1ms/step - loss: 0.4976\n",
            "Epoch 7/20\n",
            "4060/4060 [==============================] - 5s 1ms/step - loss: 0.4637\n",
            "Epoch 8/20\n",
            "4060/4060 [==============================] - 5s 1ms/step - loss: 0.4330\n",
            "Epoch 9/20\n",
            "4060/4060 [==============================] - 5s 1ms/step - loss: 0.4114\n",
            "Epoch 10/20\n",
            "4060/4060 [==============================] - 5s 1ms/step - loss: 0.3841\n",
            "Epoch 11/20\n",
            "4060/4060 [==============================] - 5s 1ms/step - loss: 0.3664\n",
            "Epoch 12/20\n",
            "4060/4060 [==============================] - 5s 1ms/step - loss: 0.3437\n",
            "Epoch 13/20\n",
            "4060/4060 [==============================] - 5s 1ms/step - loss: 0.3280\n",
            "Epoch 14/20\n",
            "4060/4060 [==============================] - 5s 1ms/step - loss: 0.3126\n",
            "Epoch 15/20\n",
            "4060/4060 [==============================] - 5s 1ms/step - loss: 0.2983\n",
            "Epoch 16/20\n",
            "4060/4060 [==============================] - 5s 1ms/step - loss: 0.2846\n",
            "Epoch 17/20\n",
            "4060/4060 [==============================] - 6s 1ms/step - loss: 0.2735\n",
            "Epoch 18/20\n",
            "4060/4060 [==============================] - 9s 2ms/step - loss: 0.2617\n",
            "Epoch 19/20\n",
            "4060/4060 [==============================] - 12s 3ms/step - loss: 0.2496\n",
            "Epoch 20/20\n",
            "4060/4060 [==============================] - 8s 2ms/step - loss: 0.2365\n",
            "Saving the model ..........\n",
            "Input_chars: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "target_chars: ['\\t', '\\n', 'ء', 'آ', 'أ', 'ؤ', 'إ', 'ئ', 'ا', 'ب', 'ة', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ي']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\amr-e\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\topology.py:2364: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  str(node.arguments) + '. They will not be included '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ag_3BwT5t3oR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "Nh0wxyBgt3oT",
        "colab_type": "code",
        "outputId": "fffd6f3c-55ba-4604-bcc9-ceea38fdffc7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from name_matching import NameMatcher\n",
        "# To calculate Accuracy, You need a list of predictions and a list of references\n",
        "\n",
        "Predictor = NameMatcher('Trained_model.h5','english')\n",
        "Prediction_list = []\n",
        "Reference_list = []\n",
        "\n",
        "print('Making predictions...............')\n",
        "### constructing the reference list and prediction list\n",
        "for ind, name in enumerate(En_list_Train):\n",
        "    list_of_en_names = name.split()\n",
        "    list_of_ar_names = Ar_list_Train[ind].split()\n",
        "    for ar_part, en_part in zip(list_of_ar_names,list_of_en_names):\n",
        "        Reference_list.append(ar_part)\n",
        "        prediction, perc = Predictor.match_name(en_part.lower())\n",
        "        Prediction_list.append(prediction[0][0])\n",
        "        #print(prediction[0])\n",
        "        #print(ar_part)\n",
        "        #print('--------------------------')\n",
        "    if ind==200:\n",
        "        break\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new instance is being created with lang:  english\n",
            "Making predictions...............\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KXptR-HQt3oa",
        "colab_type": "code",
        "outputId": "e5b7592e-2726-4a5d-939b-8f2b9ff882e7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Calculating Accuracy..................')\n",
        "### Calculating Accuracy\n",
        "# FuzzyWuzzy\n",
        "#Reference_list = ['Mohamed','Ahmad','Ali']\n",
        "#Prediction_list = ['Mohamad', 'Ahmed','Ali']\n",
        "FuzzyWuzzy_Accuracy = Predictor.calc_acc(Reference_list, Prediction_list)\n",
        "# WER\n",
        "WER_Accuracy = Predictor.WER_acc(Reference_list, Prediction_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Accuracy..................\n",
            "(FuzzyWuzzy) Accuracy = 88.66666666666667\n",
            "(WER) Train_Accuracy is  33.333333333333336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o6b66R_Mt3oi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}